# 数据湖
数据湖技术在过去几年中迅速发展，而Iceberg、Hudi和Paimon代表了这一领域的重要进展。下面是对这三个项目的技术背景和最新进展的简要介绍：

### Apache Iceberg

**技术背景**: Apache Iceberg是一个开源的表格格式，旨在改善大数据生态系统中的数据存储和访问。它提供了对大规模数据集的高效访问，同时保持与现有的数据仓库解决方案兼容。Iceberg特别关注维护大型分析数据集的复杂性，提供了强大的模式演化和版本控制功能。

**最新进展**: 近年来，Apache Iceberg逐渐获得了更广泛的社区支持和认可，成为多个大数据平台和引擎的首选表格格式。例如，Apache Spark、Trino（前PrestoSQL）、Flink和Hive等都已支持Iceberg。此外，大型云服务商也开始整合支持Iceberg，证明了它在行业中的广泛接受度和重要性。

### Apache Hudi

**技术背景**: Apache Hudi (Hadoop Upserts Deletes and Incrementals)是一个为Apache Hadoop平台打造的数据湖框架，它允许用户在大规模数据集上进行更快速的数据插入、更新和删除操作。Hudi通过提供记录级别的数据管理，能够支持即时数据流处理和更高的数据 freshness。

**最新进展**: Apache Hudi不仅被广泛地用于处理大数据湖中的数据变更问题，还在增量数据处理和实时查询优化方面取得了显著进展。Hudi的社区不断成长，为加快开发和引入新功能保驾护航。同时，Hudi已被多个数据引擎如Spark、Flink和Hive支持，体现了其在现代数据架构中的适用性和效能。

### Paimon

**技术背景**: Paimon较少被广泛认知和讨论，可能指的是一款较为特定场合或内部使用的数据技术工具，或者是一个新兴的项目。因不够普遍，关于其技术背景和功能的资料相对较少。理论上，它可能同样聚焦于数据管理、分析或存储优化等关键数据技术领域。

**最新进展**: 由于信息不足，难以具体展开Paimon的最新技术进展。如果Paimon是指特定的技术或项目，它的发展可能依赖于特定社区或团队的投入和推广。

总体而言，Iceberg和Hudi作为数据湖领域的明星项目，其技术背景和最新进展展示了数据管理技术的快速发展和日益重要性。而对于Paimon，可能需要更多的信息来进行详细介绍。这三个项目体现了数据技术领域不断演进的动态性和创新精神。


## 数据湖 VS 数据仓库

* 数据湖支持各类格式，一般是原始数据的拷贝副本以及各类业务（机器学习，BI,报表，可视化等）转换数据，数仓则要求数据结构化存储
* 数据湖成本更低，一般是对象&文件存储；
* 数据湖支持多种计算分析引擎，流批一体，而数仓通常只能满足其一；
* 支持多类存储来源，而数仓一般为HDFS/Hive等单一存储；
* 支持多类schema集成，元数据动态伸缩；
* 数据湖支持冷热分离，全生命周期覆盖；
* 数据湖一般支持ACID,update等特性；

<span style="color:#FF0000">
关键字：可扩展，schema管理，集成统一数据源，</span>

## 数据挑战

* 数据读写不可靠，事物支持难
* 数据湖数据质量差，非结构化数据易造成数据沼泽
* 数据量增加，元数据膨胀，性能变差
* 数据更新复杂，不易维护
* 数据回滚

## 开源组件

- Dalta Lake
- Hudi
- Iceberg
- Doris（查询引擎，支持hive、doris、hudi、Iceberg联邦查询）
- StarRocks+Paimon湖仓融合
- Celeborn
- Paimon

## Copy-On-Write && Merge-On-Read

Copy-On-Write 读多写少

Merge-On-Read 读少写多

## 内容

数据接入

数据搬迁

数据治理

质量管理

资产目录

访问控制

任务管理

任务编排

元数据管理等

## 解决方案调研

#### databricks-Delta Lake

流批一体，支持多数据源，兼容spark读写，ACID支持，

相关资料：https://databricks.com/wp-content/uploads/2020/12/cidr_lakehouse.pdf

主要特点：ACID、schema管理、版本控制时间旅行、流批一体、update

### Uber的Hudi

支持 Copy On Write 和 Merge On Read 的两种数据格式

### Netflix-Iceberg


### 总结

<span style="color:#FF0000">对比：</span>
- ACID
- Schema 变更支持和设计
- 流批接口支持
- 接口抽象程度和插件化
- 查询性能优化
- 其他功能
- 社区现状
### 数据湖仓架构
- 存储层
- 元数据层
- 访问层
### 数据湖方案

1.业务现状与痛点

1.1 现有业务数仓的特点
1.整个数仓围绕着HDFS/Hive进行构建，HDFS是所有的其他分层数据的源头，分层数据都分别存在HDFS中。
2.实时计算与离线计算并行进行，典型的Kappa架构。基本数据不会互通，存在重复计算。 1.2
现有业务痛点 数据探索与明细查询成本过高
越来越多业务需要提供ad-hoc方式进行查询，如果对dwd/src层数据进行查询，Hive/Presto/Spark等引擎都会受限于HDFS的性能。对于大数据量和时间跨度大的场景，查询延迟不能得到保障。为此越来越多的业务引入Doris等MPP组件，从dwd/src/dws层导入数据到Doris进行查询加速。或者直接从Kafka进行实时数据导入Doris，但这样数据的冗余会有更高的成本。

实时业务开发困难，数仓实时性不足
现有的业务实时作业都是黑盒，直接从kafka消费数据，ETL/Join等所有的业务逻辑都在Flink/Storm作业内完成，并把结果写到下游业务系统（Hbase/MySQL）。实时作业的中间状态无法查询，没有实时的DWD层数据供业务进行查询，开发复杂。

原始数据无法更新，离线计算中间数据计算过多，业务计算成本过大
SRC层数据质量无法强保障，HDFS/Hive无法支持更新操作。如果SRC层数据发生更新，需要重算把DWD/DWS层数据重新替换。另外中间层数据和预计算数据过多，计算成本消耗大。（需要查询加速需要大量预计算，非预计算的查询性能达不到要求）
2.数据湖与湖仓一体 2.1云原生数据湖（略） 存算分离的架构 统一廉价的存储（一般是S3）

2.2 湖仓一体架构

存储层 异构的低成本存储：HDFS/HDFS-EC，s3以及缓存加速。 计算层
存算分离的弹性算力，覆盖实时与离线计算引擎。 DataLake Format层（DLF）
为数据湖提供数仓的特性： 1.为data lake的数据赋予schema和管理功能，支持schema
evolution； 2.ACID支持，支持事务；支持多引擎SQL接口和update/delete以及merge
into/merge on Read功能； 3.支持流式读写特性，可以演进到流批一体和实时数仓；
4.支持权限管理，统一元数据等功能；

2.3 湖仓一体如何解决我们的问题？ 明细查询困难，中间层计算数据过多 利用Iceberg的data
skipping
feature减少查询扫描的数据量，并引入Doris用物化视图+Iceberg进行查询加速。并可以为非常用数据去除中间层数据和进行冷热分离。
常用表：Doris on DWS 非常用表：Doris on SRC/ODS


实时开发困难，实仓实时性不足
准实时业务中，利用iceberg流读流写的特性，中间层数据可以用Iceberg代替Kafka，可以查询的中间层数据。并且可以与离线作业几乎一样的SQL进行实时作业开发。

3. 目标
   为DAP演化出跟上业界技术水平的数据湖架构与平台，并为业务提供新的业务能力（实时数仓，流批一体等），并降低成本。
   2024.01产出： 完成数据湖平台v1.0版本，具备常用湖仓一体功能；
   落地一定量的典型业务； 3.1建设思路
   组件尽量保持对已有业务的兼容性，特别是离线计算引擎的支持：必须支持Spark/Presto，尽量兼容Hive。
   业务上主推查询加速以及成本优化、准实时业务等成熟和业务容易落地的目标，不追求流批一体等目标。1.0版本的业务落地，尽量避开Hive
   1.x的兼容性问题。 3.2平台目标
   单独的数据湖平台作为业务入口，具备权限管理，data-governance，数据入湖，统一元数据和匹配常用查询引擎的功能。（小铂后面详细介绍）
   3.3业务目标 落地典型业务 共享SRC层数据快速入湖，并提供准实时查询和开发能力
   整体项目迁移
   把整体项目SRC表转移到数据湖，需要兼容所有部门的所有历史任务，需要业务修改比较多。不太容易实现。
   可以尝试部分业务部门自己的项目，非共享的SRC数据（不太乐观）。
   部分业务增量新增到数据湖
   灵活把某些表新增入湖，保留原有数仓的Hive表。（这里要确认是否有兼容性问题）增量业务跑在数据湖中：

2个业务场景： 准实时明细查询（部分关键表）
部分准实时场景代替kafka，提供中间可查的实时状态 CDN数据查询加速
gaia-数据平台，查询来自Kylin数据接口api，要求秒级响应，主要为页面展示常规的dws汇总指标,但当前也面临汇总维度太多，导致维度爆炸，数据预聚合性能差，数据更新延迟的问题；
vega即席查询-OLAP，如需要对下载url进行关键字过滤再进行pv-uv的即席查询，此类查询条件不固定，因而不能直接使用dws通用的维度指标，需要dwd的明细数据才行，而当前dwd存储的历史数据量大（见图2），查询性能无法保障；
vega看板查询，固化一些常规的巡检查询逻辑，集成到vega可视化看板，查询时会传递一些明细url的关键字查询，因此涉及到明细数据查询也面临性能瓶颈；
数据湖需求： 既有聚合查询加速需求（维度多） 又有明细数据ad-hoc查询需求
明细DWD/ODS查询加速，并通过Doris external table与物化视图的能力进行冷热分层：


4. 技术选型 数据湖表格式对比

Iceberg/Hudi 等数据湖格式在相互借鉴，功能逐渐趋同
基于团队技术栈和存量业务使用资源原因，决定选择 Iceberg，后续看情况是否引入其他
数据湖管理系统 Iceberg 需要运维管理: 小文件合并、 过期快照、孤儿文件、eq-delete 转
pos-delete Iceberg 元数据访问门槛高: 元数据分散在不同文件系统/对象存储或者多个 HMS
上，缺乏统一视图 Iceberg 缺少事务冲突检测:
只有乐观并发控制（OCC），遇到冲突不断重试，效率较低
数据库有数据库管理系统（DBMS），数据湖也应该有数据湖管理系统（DLMS） Amoro
数据湖管理系统

Amoro 架构 功能特性: 数据自治:
自动执行表优化，合并小文件、删除孤儿文档、过期快照、eq-delete 转 pos-delete
数据目录: 与 HMS 自动同步数据和 schema 表更，提供查询 REST API Hive 兼容:
兼容原生 Hive，支持表升级后依然可以进行原生 Hive 的读写（Parquet 表） Iceberg
增强: 支持设置主键，主键冲突检测，支持 MQ 加速
前两个功能是开箱即用，降低开发成本；Hive 兼容是比较强的需求；Iceberg 增强则是额外
bonus。 Amoro 表格式布局

Amoro 三种存储格式: Iceberg: 原生 Iceberg Mixed-Iceberg: 增强 Iceberg
Mixed-Hive: 增强 Iceberg + 兼容 Hive

一个表有最多三个存储: LogStore: MQ 实时表存储 ChangeStore: 写优化存储（MoR）
BaseStore: 读优化存储（CoW） Amoro 局限性


5.系统架构 技术架构

湖仓存储: 以 HDFS/S3 为代表的存储系统，加上可能引入的 MQ 作为数据湖的实时存储（Amoro
特性） 表存储格式: 在已有 Hive 的基础上，引入 Iceberg，外加 Amoro 的 Mixed-Hive
和 Mixed-Iceberg 格式 湖仓管理: Amoro 作为基础的管理系统，背后以 HMS
作为元数据存储，复用 HMS 认证授权 湖仓分析: Spark/Flink/Trino 提供 Amoro
支持，Doris 以原生 Iceberg 访问对接数据湖 产品架构

数据集成: 通用集成指 EntryX、共享 SRC，新增 CDC 整库同步 存储底座：复用 HDFS
提供的缓存加速/冷热分层 数据湖湖表格式: 引入 Iceberg 实现 ACID、Schema
演化、查询加速、Update/Delete 能力，引入 Amoro 实现 Hive 兼容 湖仓管理:
统一元数据、数据自治由 Amoro 提供，平台认证授权自研对接 kerberos 湖仓计算:
多引擎兼容包括原生 Iceberg 的兼容性和 Amoro Mixed-Hive 的兼容性，SQL 接口基于
Spark/Kyuubi 提供 平台支持: 引入新平台 Lakescape，Lake + Landscape 的合成词
平台功能





