# 基本概念
## 数据仓库架构演进

数据仓库的架构演进是根据大数据技术的演进来的，从最早的单机管理，到分布式架构，从离线批处理到实时流计算，从单一结构化数据库 到数据湖，从流批分离到流批一体，从物理机到云原生

- 阶段1：传统阶段
DB:Mysql
- 阶段2: 分布式初级
Hive+HDFS
- 阶段3: 离线数仓
Spark+Hbase/Hive
- 阶段4: kappa+lambda混合模式
Kafka/db/文件+flink/spark+db
- 阶段5: 流批一体(湖仓一体)
kakfa+flink/spark+iceberg/paimon+doris/sparksql

## 常用架构

- 离线数仓
无法实时化，资源高峰
- Lambda
两套代码，多套引擎
- 实时数仓Kappa

kafka+flink+db/mpp （1.0版本）
问题：
1、kafka存不了太多数据
2、OLAP即席查询无法满足
3、数据管理方式粗放（数据血缘、数据schema、数据作业两套）
4、无法支持upsert行级别

kakfa+flink/spark+iceberg（数据湖）（2.0版本）

1、解决了存储容量的问题，hdfs之上的数据湖
2、解决了OLAP分析的瓶颈，HDFS上查询即可
3、解决了数据统一管理方式
4、无法解决upsert操作

- 流批一体（3.0）

文件系统 ：S3、HDFS
文件格式：text\orc\parquet\sequencefile
表格式：iceberg/paimon/doris
计算引擎：flink/spark
sql查询层：Spark\Presto\Hive\doris
数据管理层：amoro、生周、小文件合并、catalog管理
数据安全：脱敏加密


## 发展趋势

- 实时数仓：满足实时数据入库、分析统计以及实时自动化决策
- 大数据/数据湖：满足海量、多样复杂的数据类型（半结构化、非结构化数据），文本图像，音频等内容
Flink + Paimon + StarRocks 组合

## 使用场景
### 数据接入
数据源：cdc、文件、http接口
 输出：kafka
 客户端：http/https
 服务端：agent
 容器：docker
 db：cdc同步 

### 数据etl集成投递
 数据源：kafka
 处理：spark、flink
 输出（数仓）：elk、hive、doris、iceberg、mysql、其他db

### 数据查询

OLTP：mysql
OLAP： 
 - cube(固定模式）
 - Presto、doris灵活ad-hoc即席查询
### 数据接口
### 数据管理
 - 数据质量
 - 数据安全/权限
 - 数据资产/元数据
 - 数据地图/血缘
 - 数据成本管理/生命周期


![存算分离架构演进](../../build/html/_images/存算分离架构演进.png)

![数据分析](../../build/html/_images/数据分析.png)

### 数据监控
通用：prometheus+grafama
采集：kafka_exporter